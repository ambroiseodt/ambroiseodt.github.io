<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>I am Ambroise Odonnat, a first-year Ph.D. student at Huawei Noahâ€™s Ark Lab and Inria working on transformers and distribution shifts.</p> <p>My main focus is to theoretically and empirically study transformer-based models (e.g. ViT &amp; LLMs) when the data seen at inference differ from their training corpus. I am also interested in the optimization of neural networks.</p> <p>Previously, I obtained my masterâ€™s degree at <a href="https://ens-paris-saclay.fr/" rel="external nofollow noopener" target="_blank">ENS Paris-Saclay</a> in 2023 from the Mathematics, Vision, and Machine Learning (<a href="https://www.master-mva.com/" rel="external nofollow noopener" target="_blank">MVA</a>) program. I also hold an engineering degree from <a href="https://en.wikipedia.org/wiki/%C3%89cole_des_ponts_ParisTech" rel="external nofollow noopener" target="_blank">Ecole des Ponts ParisTech</a> in mathematics and computer science.</p> <p>I maintain a research blog called <a href="https://logb-research.github.io/" rel="external nofollow noopener" target="_blank">logB</a><a></a> with my friend <a href="https://www.oussamazekri.fr/" rel="external nofollow noopener" target="_blank">Oussama Zekri</a><a></a>. Feel free to check it out ðŸ™ƒ. Donâ€™t hesitate to reach out for possible collaborations or questions regarding my research!</p> </body></html>