---
---

@article{zekri2024llm,
      title={Large Language Models as Markov Chains}, 
      author={Zekri*, Oussama and Odonnat*, Ambroise and Benecheab, Abdelhakim and Bleistein, Linus and Boulle, Nicolas and Redko*, Ievgen},
      preprint={Preprint},
      year={2024},
      arxiv={2410.02724},
      pdf={https://arxiv.org/pdf/2410.02724},
      abstract={Large language models (LLMs) have proven to be remarkably efficient, both across a wide range of natural language processing tasks and well beyond them. However, a comprehensive theoretical analysis of the origins of their impressive performance remains elusive. In this paper, we approach this challenging task by drawing an equivalence between generic autoregressive language models with vocabulary of size T and context window of size K and Markov chains defined on a finite state space of size O(T^K). We derive several surprising findings related to the existence of a stationary distribution of Markov chains that capture the inference power of LLMs, their speed of convergence to it, and the influence of the temperature on the latter. We then prove pre-training and in-context generalization bounds and show how the drawn equivalence allows us to enrich their interpretation. Finally, we illustrate our theoretical guarantees with experiments on several recent LLMs to highlight how they capture the behavior observed in practice.},
      selected = {true},
      preview={llm_preview.png},
      slides = {https://drive.google.com/file/d/1Zid7be_O1kM8uvO88yLVxIInWLRIkwT-/view?usp=sharing}
}

@article{ilbert2024rmt,
      title={Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting}, 
      author={Ilbert, Romain and Tiomoko, Malik and Louard, Cosme and Odonnat, Ambroise and Feofanov, Vasilii and Plapanas, Themis and Redko, Ievgen},
      journal={NeurIPS Spotlight},
      year={2024},
      arxiv={2406.10327},
      pdf={https://arxiv.org/pdf/2406.10327},
      abstract={In this paper, we introduce a novel theoretical framework for multi-task regression, applying random matrix theory to provide precise performance estimations, under high-dimensional, non-Gaussian data distributions. We formulate a multi-task optimization problem as a regularization technique to enable single-task models to leverage multi-task learning information. We derive a closed-form solution for multi-task optimization in the context of linear models. Our analysis provides valuable insights by linking the multi-task learning performance to various model statistics such as raw data covariances, signal-generating hyperplanes, noise levels, as well as the size and number of datasets. We finally propose a consistent estimation of training and testing errors, thereby offering a robust foundation for hyperparameter optimization in multi-task regression scenarios. Experimental validations on both synthetic and real-world datasets in regression and multivariate time series forecasting demonstrate improvements on univariate models, incorporating our method into the training loss and thus leveraging multivariate information.},
      selected = {true},
      preview={logo_ts.png},
}

@article{xie2024mano,
      title={MANO: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts}, 
      author={Xie*, Renchunzi and Odonnat*, Ambroise and Feofanov*, Vasilii and Deng, Weijian and Zhang, Jianfeng and An, Bo},
      journal={NeurIPS},
      year={2024},
      arxiv={2405.18979},
      pdf={https://arxiv.org/pdf/2405.18979},
      abstract={Estimating test accuracy without access to the ground-truth test labels under varying test environments is a challenging, yet extremely important problem in the safe deployment of machine learning algorithms. Existing works rely on the information from either the outputs or the extracted features of neural networks to formulate an estimation score correlating with the ground-truth test accuracy. In this paper, we investigate--both empirically and theoretically--how the information provided by the gradients can be predictive of the ground-truth test accuracy even under a distribution shift. Specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our key idea is that the model should be adjusted with a higher magnitude of gradients when it does not generalize to the test dataset with a distribution shift. We provide theoretical insights highlighting the main ingredients of such an approach ensuring its empirical success. Extensive experiments conducted on diverse distribution shifts and model structures demonstrate that our method significantly outperforms state-of-the-art algorithms.},
      selected = {true},
      preview={logo_hands.png},
      poster = {neurips_2024_mano_poster.pdf},
      code = {https://github.com/Renchunzi-Xie/MaNo}
}

@article{ilbert2024unlocking,
      title={SAMformer: Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention}, 
      author={Ilbert*, Romain and Odonnat*, Ambroise and Feofanov, Vasilii and Virmaux, Aladin and Paolo, Giuseppe and Palpanas, Themis and Redko, Ievgen},
      journal={ICML Oral},
      year={2024},
      arxiv={2402.10198},
      pdf={https://arxiv.org/pdf/2402.10198.pdf},
      abstract={Transformer-based architectures achieved breakthrough performance in natural language processing and computer vision, yet they remain inferior to simpler linear baselines in multivariate long-term forecasting. To better understand this phenomenon, we start by studying a toy linear forecasting problem for which we show that transformers are incapable of converging to their true solution despite their high expressive power. We further identify the attention of transformers as being responsible for this low generalization capacity. Building upon this insight, we propose a shallow lightweight transformer model that successfully escapes bad local minima when optimized with sharpness-aware optimization. We empirically demonstrate that this result extends to all commonly used real-world multivariate time series datasets. In particular, SAMformer surpasses the current state-of-the-art model TSMixer by 14.33% on average, while having ~4 times fewer parameters. The code is available at https://github.com/romilbert/samformer.},
      selected = {true},
      preview={transformers.png},
      code={https://github.com/romilbert/samformer},
      poster={icml_2024_samformer_poster.pdf},
      slides={Presentation_ICML_2024_Generic.pdf},
      pmlr={https://proceedings.mlr.press/v235/ilbert24a.html}
}

@article{odonnat2024leveraging,
      title={Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias},
      author={Odonnat, Ambroise and Feofanov, Vasilii and Redko, Ievgen},
      journal={AISTATS},
      year={2024},
      arxiv={2310.14814},
      pdf={https://arxiv.org/pdf/2310.14814},
      abstract={Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, although they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraints. To address this issue, we propose a novel confidence measure, called $\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on classification datasets of various data modalities. The code is available at https://github.com/ambroiseodt/tsim.},
      selected={true},
      preview={diversity.png},
      code={https://github.com/ambroiseodt/tsim},
      poster={aistats_2024_leveraging_poster.pdf},
      slides={Presentation_AISTATS_2024_Generic.pdf},
      pmlr={https://proceedings.mlr.press/v238/odonnat24a}
}

@article{xie2024leveraging,
      title={Leveraging Gradients for Unsupervised Accuracy Estimation under Distribution Shift}, 
      author={Xie, Renchunzi and Odonnat, Ambroise and Feofanov, Vasilii and Redko, Ievgen and Zhang, Jianfeng and An, Bo},
      preprint={Preprint},
      year={2024},
      arxiv={2401.08909},
      pdf={https://arxiv.org/pdf/2401.08909.pdf},
      abstract={Estimating test accuracy without access to the ground-truth test labels under varying test environments is a challenging, yet extremely important problem in the safe deployment of machine learning algorithms. Existing works rely on the information from either the outputs or the extracted features of neural networks to formulate an estimation score correlating with the ground-truth test accuracy. In this paper, we investigate--both empirically and theoretically--how the information provided by the gradients can be predictive of the ground-truth test accuracy even under a distribution shift. Specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our key idea is that the model should be adjusted with a higher magnitude of gradients when it does not generalize to the test dataset with a distribution shift. We provide theoretical insights highlighting the main ingredients of such an approach ensuring its empirical success. Extensive experiments conducted on diverse distribution shifts and model structures demonstrate that our method significantly outperforms state-of-the-art algorithms.},
      selected = {false},
      preview={neural_network.png}
}

@article{odonnat2022detection,
      title={Detection of interictal epileptiform discharges on EEG and MEG}, 
      author={Odonnat, Ambroise and Nasiotis, Konstantinos and Hill, Eleanor and Ebrahimi Kahou, Samira and Gnassounou, Theo and Zheng, Jiayue and Karthik Enamundram, Naga and Baillet, Sylvain and Dudley, Roy and Cohen-Adad, Julien},
      journal={QBIN Scientific Day},
      year={2022},
      html={https://event.fourwaves.com/fr/qbinscientificday2022/resumes/ad70d0ce-32ea-4a71-9e45-6ec34d772363},
      pdf={https://cdn.fourwaves.com/static/media/formdata/985f0c64-8ac6-4c6f-a03c-146a28691c26/a2be897c-4143-4f85-831d-192e205cece6.pdf},
      abstract={Epilepsy is the fourth most common neurological disorder in the world. It affects the central nervous system, leading to abnormal brain activity which causes seizures that are sometimes accompanied by loss of consciousness. Electroencephalography (EEG) and magnetoencephalography (MEG) recordings contain patterns of abnormal brain activity such as interictal epileptiform discharges (IEDs), also known as spikes, that aid in the diagnosis of epilepsy and the identification of the epileptogenic zone. Due to the long recording time, high number of channels, and their noisy nature such recordings are tedious and time consuming to manually analyze. These challenges have motivated the development of automated methods to detect epileptic spikes. Convolutional and Recurrent Neural Networks are among the most frequently chosen architectures for their feature extraction capacities. However, both methods have limited global dependencies perception and recurrent networks lack efficiency because the steps cannot be parallelized. We developed a model based on a transformer architecture. Transformers are a breakthrough in the fields of Natural Language Processing and Computer Vision. They rely on a self-attention mechanism, which enables to differentially weight the significance of each part of the input data enhancing relevant ones while diminishing others. The aim of our framework is to detect spikes on EEG and/or MEG signals while being agnostic to the number of channels. First, the raw data is preprocessed (artifact removal, notch filter, etc.) and split into 2-second segments called ‘trials’ using the open-source Brainstorm software (https://neuroimage.usc.edu/brainstorm/). Spatial filtering is performed before applying the attention mechanism on the feature-channel dimension to focus on relevant channels. Then, embeddings of each time point are created before entering a transformer encoder to perceive global temporal dependencies. The output of the encoder is a highly distinguishable representation of the trial containing spatial and temporal information. The last block is composed of two fully-connected layers separated by a Mish activation function. It splits the data into 10 time windows and gives the probability of presence of a spike for each time window. Preliminary experiments were conducted on a single pediatric participant. A repeated 5-fold cross-validation strategy was used for training and validation. The first experimental results are promising with an accuracy of 90% and a F1-score of 70%. Our model has good potential for spatial and temporal features learning on EEG and MEG signals. The next step is to perform cross-subject spike detection to have a robust framework usable in real-world situations.},
      selected = {false},
      preview={eeg_icon.png},
      slides={eeg_detection.pdf},
      award={Best Flash Talk}
}



